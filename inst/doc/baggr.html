<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />

<meta name="author" content="Rachael Meager, Witold Wiecek" />

<meta name="date" content="2024-02-12" />

<title>Aggregating Average Treatment Effects with baggr</title>

<script>// Pandoc 2.9 adds attributes on both header and div. We remove the former (to
// be compatible with the behavior of Pandoc < 2.8).
document.addEventListener('DOMContentLoaded', function(e) {
  var hs = document.querySelectorAll("div.section[class*='level'] > :first-child");
  var i, h, a;
  for (i = 0; i < hs.length; i++) {
    h = hs[i];
    if (!/^h[1-6]$/i.test(h.tagName)) continue;  // it should be a header h1-h6
    a = h.attributes;
    while (a.length > 0) h.removeAttribute(a[0].name);
  }
});
</script>

<style type="text/css">
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
</style>



<style type="text/css">
code {
white-space: pre;
}
.sourceCode {
overflow: visible;
}
</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
{ counter-reset: source-line 0; }
pre.numberSource code > span
{ position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
{ content: counter(source-line);
position: relative; left: -1em; text-align: right; vertical-align: baseline;
border: none; display: inline-block;
-webkit-touch-callout: none; -webkit-user-select: none;
-khtml-user-select: none; -moz-user-select: none;
-ms-user-select: none; user-select: none;
padding: 0 4px; width: 4em;
color: #aaaaaa;
}
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }
div.sourceCode
{ }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } 
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.at { color: #7d9029; } 
code span.bn { color: #40a070; } 
code span.bu { color: #008000; } 
code span.cf { color: #007020; font-weight: bold; } 
code span.ch { color: #4070a0; } 
code span.cn { color: #880000; } 
code span.co { color: #60a0b0; font-style: italic; } 
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.do { color: #ba2121; font-style: italic; } 
code span.dt { color: #902000; } 
code span.dv { color: #40a070; } 
code span.er { color: #ff0000; font-weight: bold; } 
code span.ex { } 
code span.fl { color: #40a070; } 
code span.fu { color: #06287e; } 
code span.im { color: #008000; font-weight: bold; } 
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.kw { color: #007020; font-weight: bold; } 
code span.op { color: #666666; } 
code span.ot { color: #007020; } 
code span.pp { color: #bc7a00; } 
code span.sc { color: #4070a0; } 
code span.ss { color: #bb6688; } 
code span.st { color: #4070a0; } 
code span.va { color: #19177c; } 
code span.vs { color: #4070a0; } 
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } 
</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    var j = 0;
    while (j < rules.length) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") {
        j++;
        continue;
      }
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') {
        j++;
        continue;
      }
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>



<style type="text/css">

div.csl-bib-body { }
div.csl-entry {
clear: both;
margin-bottom: 0em;
}
.hanging div.csl-entry {
margin-left:2em;
text-indent:-2em;
}
div.csl-left-margin {
min-width:2em;
float:left;
}
div.csl-right-inline {
margin-left:2em;
padding-left:1em;
}
div.csl-indent {
margin-left: 2em;
}
</style>

<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; } 
code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">Aggregating Average Treatment Effects with
baggr</h1>
<h4 class="author">Rachael Meager, Witold Wiecek</h4>
<h4 class="date">2024-02-12</h4>


<div id="TOC">
<ul>
<li><a href="#data-inputs-reported-effects-or-full-individual-level-data-sets" id="toc-data-inputs-reported-effects-or-full-individual-level-data-sets">Data
inputs: reported effects or full individual-level data sets</a></li>
<li><a href="#ate-aggregation-models-in-baggr" id="toc-ate-aggregation-models-in-baggr">ATE aggregation models in
<em>baggr</em></a></li>
<li><a href="#models-their-inputs-likelihood-and-priors-a-summary-table" id="toc-models-their-inputs-likelihood-and-priors-a-summary-table">Models,
their inputs, likelihood and priors: a summary table</a></li>
<li><a href="#prior-choice-in-baggr" id="toc-prior-choice-in-baggr">Prior choice in baggr</a></li>
<li><a href="#running-the-rubin-model-in-baggr" id="toc-running-the-rubin-model-in-baggr">Running the Rubin Model in
<em>baggr</em></a>
<ul>
<li><a href="#choosing-priors" id="toc-choosing-priors">Choosing
priors</a></li>
</ul></li>
<li><a href="#understanding-and-criticising-baggr-model-performance" id="toc-understanding-and-criticising-baggr-model-performance">Understanding
and criticising <em>baggr</em> model performance</a></li>
<li><a href="#measuring-pooling" id="toc-measuring-pooling">Measuring
“pooling”</a>
<ul>
<li><a href="#estimate-of-pooling-in-each-group" id="toc-estimate-of-pooling-in-each-group">Estimate of pooling in each
group</a></li>
<li><a href="#overall-pooling-in-the-model" id="toc-overall-pooling-in-the-model">Overall pooling (in the
model)</a></li>
</ul></li>
<li><a href="#plotting-and-model-comparison-in-baggr" id="toc-plotting-and-model-comparison-in-baggr">Plotting and model
comparison in <em>baggr</em></a>
<ul>
<li><a href="#basic-model-comparison-with-baggr_compare" id="toc-basic-model-comparison-with-baggr_compare">Basic model
comparison with <em>baggr_compare</em></a></li>
<li><a href="#comparing-existing-models-understanding-impact-of-the-prior" id="toc-comparing-existing-models-understanding-impact-of-the-prior">Comparing
existing models, understanding impact of the prior</a></li>
<li><a href="#forest-plots-for-the-models" id="toc-forest-plots-for-the-models">Forest plots for the
models</a></li>
</ul></li>
<li><a href="#cross-validation-in-baggr" id="toc-cross-validation-in-baggr">Cross-validation in
<em>baggr</em></a></li>
<li><a href="#references" id="toc-references">References</a></li>
</ul>
</div>

<p>This vignette is written for <em>baggr</em> users who want to learn
about (Bayesian) meta-analysis concepts and analyse data on typically
continuous variables. If you are looking for information that is more
specific to binary data, please read
<code>vignette(&quot;baggr_binary&quot;)</code>. This article - like the package
itself - is still under construction. We encourage your feedback.</p>
<p><em>baggr</em> (pronounced “bagger” or “badger” and short for
Bayesian Aggregator) is a package for aggregating evidence on causal
effects measured in several separate and different instances. These
instances may be different studies, groups, locations or “sites” however
conceptualised. We refer to these separate pieces of evidence as
“groups” for the remainder of this vignette When each group is a study,
the model is that of <em>meta-analysis</em>, but aggregation of evidence
is not limited to this case.</p>
<p>One of the most basic objects of interest is the <em><a href="http://www.fsb.muohio.edu/lij14/420_paper_Rubin74.pdf">average
treatment effect (ATE)</a></em>, the difference in the mean outcome in
treatment and control groups; for more information see work by <span class="citation">Rubin (1974)</span>. In meta-analysis we are often
interested in the average of this average effect across groups,
estimated using all the evidence from all the groups. Consider the case
where the evidence in each study or group is generated by comparing the
outcomes of treatment and control samples in a randomized experiment. We
will ignore any covariate information at the individual or group level
for now.</p>
<p>Consider some outcome of interest <span class="math inline">\(y_{ik}\)</span> such as consumption, income or
health outcomes for a household or individual <span class="math inline">\(i = 1,2,...N_k\)</span> in study group <span class="math inline">\(k = 1,2....K\)</span>. Let <span class="math inline">\(Y_k\)</span> denote the <span class="math inline">\(N_k\)</span>-length vector of observed outcomes
from group <span class="math inline">\(k\)</span>. Denote the binary
indicator of treatment status by <span class="math inline">\(T_{ik}\)</span>, and denote by <span class="math inline">\(T_k\)</span> the <span class="math inline">\(N_k\)</span>-length vector of all treatment status
indicators from group <span class="math inline">\(k\)</span>.</p>
<p>Suppose that <span class="math inline">\(y_{ik}\)</span> varies
randomly around its mean <span class="math inline">\(\mu_k + \tau_k
T_i\)</span>. In this setting <span class="math inline">\(\tau_k\)</span> is the treatment effect in group
<span class="math inline">\(k\)</span>. The random variation in <span class="math inline">\(y_{ik}\)</span> may be the result of sampling
variation or measurement error, as in the <span class="citation">Rubin
(1981)</span> model, or it may be the result of unmodelled heterogeneity
or uncertainty in outcomes for individuals within the group. Allow the
variance of the outcome variable <span class="math inline">\(y_{ik}\)</span> to vary across sites, so <span class="math inline">\(\sigma_{y_k}^2\)</span> may differ across <span class="math inline">\(k\)</span>.</p>
<div id="data-inputs-reported-effects-or-full-individual-level-data-sets" class="section level2">
<h2>Data inputs: reported effects or full individual-level data
sets</h2>
<p>For average effects aggregation, <em>baggr</em> allows 3 types of
data inputs. The user may supply, within a data frame environment, any
of the following:</p>
<ol style="list-style-type: decimal">
<li><p>A set of estimated treatment effects <span class="math inline">\(\{\hat{\tau_k}\}_{k=1}^{K}\)</span> and their
standard errors <span class="math inline">\(\{\hat{se_k}\}_{k=1}^{K}\)</span> from each study.
This should be formatted as two column vectors of length <span class="math inline">\(K\)</span> within the data frame, where <span class="math inline">\(\hat{\tau_k}\)</span> is the <span class="math inline">\(k\)</span>-th entry of the treatment effect vector
and <span class="math inline">\(\hat{se_k}\)</span> is the <span class="math inline">\(k\)</span>-th entry of the standard errors vector.
Columns should be named <code>&quot;tau&quot;</code> and <code>&quot;se&quot;</code>. Model
will be <code>&quot;rubin&quot;</code> (see below).</p></li>
<li><p>A set of control group means and estimated treatment effects
<span class="math inline">\(\{\hat{\mu_k},\hat{\tau_k}\}_{k=1}^{K}\)</span>,
as well as the standard errors for both <span class="math inline">\(\{\hat{se}_{\mu k}, \hat{se}_{\tau
k}\}_{k=1}^{K}\)</span>, for each study site This should be formatted as
four vectors of length <span class="math inline">\(K\)</span> within the
data frame, analogous to the above. Columns should be names
<code>&quot;mu&quot;</code>, <code>&quot;tau&quot;</code>, <code>&quot;se.mu&quot;</code>,
<code>&quot;se.tau&quot;</code>. Model will be <code>&quot;mutau&quot;</code> (see
below).</p></li>
<li><p>The full data sets from all the original studies <span class="math inline">\(\{Y_k, T_k\}_{k=1}^{K}\)</span>. This should be
formatted as three vectors of length <span class="math inline">\(\sum_{k=1}^K N_{k}\)</span>, which we recommend
naming <code>&quot;outcome&quot;</code>, <code>&quot;treatment&quot;</code>,
<code>&quot;group&quot;</code> (for site indicators), but the names can also be
specified when calling <code>baggr()</code> function. Model will be
<code>&quot;rubin_full&quot;</code> (see below).</p></li>
</ol>
<p>As an example of an individual-level data set we include in data
frames <code>microcredit</code> and <code>microcredit_simplified</code>.
The former contains all the microcredit outcome data used in <span class="citation">Meager (2019)</span>, standardized to USD PPP in 2009
terms per two weeks (a time period is necessary as these are flow
variables). It therefore contains NAs and other undesirable features, to
allow the user to see how <em>baggr</em> handles these common data
issues. The data set <code>microcredit_simplified</code> has these
issues cleaned up and contains only one outcome of interest, consumer
durables spending.</p>
<p><em>baggr</em> also has a function that automatically produces
summary data from full data sets, in case one wishes to run the
comparatively faster summary-data models. The <code>prepare_ma()</code>
function applied to a dataframe with columns named <code>&quot;group&quot;</code>,
<code>&quot;outcome&quot;</code>, and <code>&quot;treatment&quot;</code> automatically
estimates the control group means, treatment effects, and associated
standard errors for each group using an Ordinary Least Squares
regression. The resulting output is already formatted as a valid input
to the <code>baggr()</code> command itself:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="fu">prepare_ma</span>(microcredit_simplified, <span class="at">outcome =</span> <span class="st">&quot;consumption&quot;</span>)</span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="co">#&gt;   group       mu       tau     se.mu    se.tau n.mu n.tau</span></span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a><span class="co">#&gt; 1     1 303.6065  5.510755  2.559897  4.101140 8298  8262</span></span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a><span class="co">#&gt; 2     2 280.0887 50.449393 11.141075 22.156317  260   701</span></span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a><span class="co">#&gt; 3     3 196.4215 -5.171338 14.432604 19.266339  444   551</span></span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a><span class="co">#&gt; 4     4 276.2791  4.641604  3.730907  5.451094 3248  3579</span></span>
<span id="cb1-7"><a href="#cb1-7" tabindex="-1"></a><span class="co">#&gt; 5     5 327.5246 -2.935731  4.027768  6.022955 2771  2716</span></span></code></pre></div>
</div>
<div id="ate-aggregation-models-in-baggr" class="section level2">
<h2>ATE aggregation models in <em>baggr</em></h2>
<p><em>baggr</em> currently contains two different models suitable for
aggregating sets of average treatment effects. Consider first the
evidence aggregation model from <span class="citation">Rubin
(1981)</span>, discussed extensively in Chapter 5 of <span class="citation">Gelman et al. (2013)</span>; the model consists of a
hierarchical likelihood as follows:</p>
<p><span class="math display">\[\begin{equation}
\begin{aligned}
\hat{\tau_k} &amp;\sim N(\tau_k, \hat{se_k}^2) \; \forall \; k \\
\tau_k &amp;\sim N(\tau, \sigma_{\tau}^2) \; \forall \; k .
\end{aligned}
\label{rubin model}
\end{equation}\]</span></p>
<p>The motivation for this model structure is discussed in detail in the
sources above and in <span class="citation">Meager (2019)</span>. To
complete the Bayesian model, we now need priors. <em>baggr</em> has a
set of default priors for each model (adjusted to data), as well as
allowing the user to specify her own priors if desired. In the Rubin
model, <em>baggr</em>’s default priors on the hyper-parameters are as
follows:</p>
<ul>
<li>For <span class="math inline">\(\tau\)</span>, the prior is <span class="math inline">\(\mathcal{N}(0, 100)\)</span>. This is a very weak
prior which does little regularization as a default, centered at zero.
It assumes that causal effects should not be thought of as large unless
data contains evidence to the contrary (a “hand-wavey” form of Occam’s
Razor).</li>
<li>For <span class="math inline">\(\sigma_{\tau}\)</span> the prior is
<span class="math inline">\(\textrm{Uniform}(0,10\tilde{\sigma})\)</span>,
where <span class="math inline">\(\tilde{\sigma}\)</span> is a naive
standard deviance estimator for <span class="math inline">\(\{\hat{\tau_k}\}_{k=1}^{K}\)</span> (generated by
the R command <code>sd()</code>).</li>
</ul>
<p>In case you also have data on the control groups’ mean outcomes and
the uncertainty on those,you can augment the <span class="citation">Rubin (1981)</span> model to incorporate that
information. Following <span class="citation">Meager (2019)</span>, if
one has access to the estimated control means <span class="math inline">\(\{\hat{\mu_k}\}^K_{k=1}\)</span> and their
standard errors <span class="math inline">\(\{\hat{se}_{\mu
k}\}^K_{k=1}\)</span>, one can fit a joint Gaussian model on the pairs
<span class="math inline">\(\{\hat{\mu_k},\hat{\tau_k}\}_{k=1}^{K}\)</span>:</p>
<p><span class="math display">\[\begin{equation}
\begin{aligned}
\hat{\tau_k} &amp;\sim N(\tau_k, \hat{se_{\tau k}}^2) \; \forall \; k \\
\hat{\mu_k} &amp;\sim N(\mu_k, \hat{se_{\mu k}}^2) \; \forall \; k \\
\left( \begin{array}{c}
\mu_{k}\\
\tau_{k}
\end{array} \right)
&amp;\sim
N\left( \left(
\begin{array}{c}
\mu\\
\tau
\end{array} \right), V \right) \; \text{where} \;V = \left[
\begin{array}{cc} \sigma^2_{\mu} &amp; \sigma_{\tau\mu} \\
\sigma_{\tau\mu} &amp; \sigma_{\tau}^2 \end{array} \right]\forall \; k.
\\
\end{aligned}
\label{full data model}
\end{equation}\]</span></p>
<p>In <em>baggr</em> this model is referred to as
<code>&quot;mutau&quot;</code>.</p>
<p>If you have only few groups, the priors on <span class="math inline">\(V\)</span> will need to be relatively strong to
avoid overfitting. See <span class="citation">Meager (2019)</span> for
more discussion of this issue in particular, or see the <a href="https://mc-stan.org/docs/2_18/stan-users-guide/multivariate-hierarchical-priors-section.html">Stan
Manual on hierarchical priors</a>. The default priors are as
follows:</p>
<ul>
<li><span class="math inline">\(V\)</span> is decomposed into a
correlation matrix <span class="math inline">\(\Omega\)</span>, which
receives an LKJCorr(3) prior regularizing it towards independence, and a
scale parameter <span class="math inline">\(\theta\)</span> which
receives a <span class="math inline">\(\textrm{Cauchy}(0,s)\)</span>
prior, with <span class="math inline">\(s\)</span> set to either 10
times the empirical SD of <span class="math inline">\(\mu\)</span> of of
<span class="math inline">\(\tau\)</span>, whichever is higher.</li>
<li>The default prior for <span class="math inline">\((\mu,
\tau)\)</span> is bivariate Gaussian, with zero means and a diagonal
covariance matrix with the diagonal (variances) set to 100 times the
empirical maximum of <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\tau\)</span>.</li>
</ul>
</div>
<div id="models-their-inputs-likelihood-and-priors-a-summary-table" class="section level2">
<h2>Models, their inputs, likelihood and priors: a summary table</h2>
<!-- This is a mess to edit, sorry. But it presents nicely in Markdown -->
<table>
<colgroup>
<col width="12%" />
<col width="20%" />
<col width="30%" />
<col width="25%" />
<col width="11%" />
</colgroup>
<thead>
<tr class="header">
<th>Model (name in <code>baggr</code>)</th>
<th>Input columns</th>
<th>Level-1 likelihood</th>
<th>Level-2 likelihood</th>
<th>Default priors</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>summary data “Rubin” (<code>&quot;rubin&quot;</code>)</td>
<td><code>tau</code> and <code>se</code></td>
<td><span class="math inline">\(\hat{\tau_k} \sim N(\tau_k,
\hat{se_k}^2)\)</span></td>
<td><span class="math inline">\(\tau_k \sim N(\tau,
\sigma_{\tau}^2)\)</span></td>
<td><span class="math inline">\(\tau \sim \mathcal{N}(0, 100)\)</span>,
<span class="math inline">\(\sigma_{\tau} \sim \mathcal{U}(0,
10\tilde{\sigma})\)</span></td>
</tr>
<tr class="even">
<td>“<span class="math inline">\(\mu\)</span> and <span class="math inline">\(\tau\)</span>” (<code>&quot;mutau&quot;</code>)</td>
<td><code>tau</code>, <code>mu</code>, <code>se.tau</code>,
<code>se.mu</code></td>
<td><span class="math inline">\(\hat{\tau_k} \sim N(\tau_k,
\hat{se_{\tau,k}}^2)\)</span>, <span class="math inline">\(\hat{\mu_k}
\sim N(\mu_k, \hat{se_{\mu,k}}^2)\)</span></td>
<td><span class="math inline">\(\pmatrix{\mu_k \\ \tau_k} \sim
N(\pmatrix{\mu \\ \tau}, V)\)</span></td>
<td><span class="math inline">\(V = \theta \Omega \theta&#39;\)</span>
where <span class="math inline">\(\theta \sim Cauchy(0,10)\)</span>,
<span class="math inline">\(\Omega \sim LKJ(3)\)</span>, <span class="math inline">\(\pmatrix{\mu \\ \tau} \sim N(0,100^2Id_2
)\)</span></td>
</tr>
<tr class="odd">
<td>full data “Rubin” (<code>&quot;rubin_full&quot;</code>)</td>
<td><code>outcome</code>, <code>treatment</code>,
<code>group</code></td>
<td>Same as for “<span class="math inline">\(\mu\)</span> and <span class="math inline">\(\tau\)</span>”</td>
<td>Same as for “<span class="math inline">\(\mu\)</span> and <span class="math inline">\(\tau\)</span>”</td>
<td>Same as for “<span class="math inline">\(\mu\)</span> and <span class="math inline">\(\tau\)</span>”</td>
</tr>
<tr class="even">
<td>Logit (<code>&quot;logit&quot;</code>)</td>
<td><code>outcome</code>, <code>treatment</code>,
<code>group</code></td>
<td>See <code>vignette(&quot;baggr_binary&quot;)</code></td>
<td>…</td>
<td>…</td>
</tr>
</tbody>
</table>
<!-- | Quantiles (`"quantiles"`)         | `outcome`, `treatment`, `group`  | See Meager (2019)    | See Meager (2019)          | See Meager (2019)  | -->
<p>Where inputs are individual-level data, i.e. <code>outcome</code>,
<code>treatment</code>, <code>group</code>, you can specify column names
in as arguments to <code>baggr()</code> function.</p>
</div>
<div id="prior-choice-in-baggr" class="section level2">
<h2>Prior choice in baggr</h2>
<p>In the “Rubin” and “<span class="math inline">\(\mu\)</span> and
<span class="math inline">\(\tau\)</span>” models, the user can specify
custom priors beyond the defaults using the prior arguments. These prior
arguments are subdivided into 3 categories:</p>
<ul>
<li><p>Priors for the hypermean, the average effect across groups, such
as <span class="math inline">\(\tau\)</span> or the vector <span class="math inline">\((\mu, \tau)\)</span>. This is denoted using the
<code>prior_hypermean</code> argument in baggr.</p></li>
<li><p>Priors for the hyper-standard-deviations <span class="math inline">\(\sigma_{\tau}\)</span>, the standard deviation of
effects across groups. This also refers to the prior on <span class="math inline">\(\theta\)</span>, the scale parameter of the
hyper-variance-covariance matrix <span class="math inline">\(V\)</span>
in the”<span class="math inline">\(\mu\)</span> and <span class="math inline">\(\tau\)</span>” model. This type of parameter is
denoted <code>prior_hypersd</code> in baggr.</p></li>
<li><p>Priors on hypercorrelations between parameters that may co-vary
across the groups. When working with multi-dimensional parameters at the
upper level of the model (aka performing multivariate shrinkage), this
is the correlation in the distribution of the different parameters
across the groups. For example, in the “<span class="math inline">\(\mu\)</span> and <span class="math inline">\(\tau\)</span>” model this parameter is the
correlation matrix <span class="math inline">\(\Omega\)</span> that
governs the hyper-variance-covariance matrix <span class="math inline">\(V\)</span>. This type of parameter is denoted
<code>prior_hypercor</code> in baggr.</p></li>
</ul>
<p>The possible prior distributions we allow for in the current version
are:</p>
<ul>
<li>For <code>prior_hypermean</code> we allow <code>&quot;normal&quot;</code>,
<code>&quot;uniform&quot;</code>, <code>&quot;cauchy&quot;</code>, <code>&quot;lognormal&quot;</code>,
and (generalised) <code>&quot;student_t&quot;</code> with any parameter values
which are logically possible given support constraints (e.g. user cannot
specify a negative variance on a normal distribution or a negative scale
on a Cauchy) When the model has a vector hypermean, “<span class="math inline">\(\mu\)</span> and <span class="math inline">\(\tau\)</span>” model, baggr applies the given
prior to all the elements of the vector independently. If the user
wishes to specify a prior dependence between the components, one can
supply prior_hypermean with a multinormal argument (see
<code>?priors</code> for details).</li>
<li>For <code>prior_hypersd</code> we allow <code>&quot;normal&quot;</code> and
<code>&quot;uniform&quot;</code> with any parameter values which are logically
possible given support constraints (as above).</li>
<li>For <code>prior_hypercor</code>, which is only necessary when there
is a multivariate shrinkage operation (as in the “<span class="math inline">\(\mu\)</span> and <span class="math inline">\(\tau\)</span>” model) we allow an LKJ correlation
prior (<code>&quot;lkj&quot;</code>) with any parameter values which are logically
possible given support constraints. For further details of this strategy
see Meager (2019).</li>
</ul>
<p>Notation for priors is “plain-text”, in that you can write the
distributions as <code>normal()</code>, <code>uniform()</code> etc. See
<code>?priors</code> for details, or continue to the example below with
the Rubin model.</p>
</div>
<div id="running-the-rubin-model-in-baggr" class="section level2">
<h2>Running the Rubin Model in <em>baggr</em></h2>
<p>To demonstrate the Rubin model in <em>baggr</em>, consider the 8
schools example from Rubin (1981). In this dataset, 8 schools in the
United States performed similar randomized experiments to estimate the
causal effect of an SAT tutoring program on learning outcomes. Reported
treatment effects and their standard errors are included in
<em>baggr</em> as a data frame:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a>schools</span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a><span class="co">#&gt;      group tau se</span></span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a><span class="co">#&gt; 1 School A  28 15</span></span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a><span class="co">#&gt; 2 School B   8 10</span></span>
<span id="cb2-5"><a href="#cb2-5" tabindex="-1"></a><span class="co">#&gt; 3 School C  -3 16</span></span>
<span id="cb2-6"><a href="#cb2-6" tabindex="-1"></a><span class="co">#&gt; 4 School D   7 11</span></span>
<span id="cb2-7"><a href="#cb2-7" tabindex="-1"></a><span class="co">#&gt; 5 School E  -1  9</span></span>
<span id="cb2-8"><a href="#cb2-8" tabindex="-1"></a><span class="co">#&gt; 6 School F   1 11</span></span>
<span id="cb2-9"><a href="#cb2-9" tabindex="-1"></a><span class="co">#&gt; 7 School G  18 10</span></span>
<span id="cb2-10"><a href="#cb2-10" tabindex="-1"></a><span class="co">#&gt; 8 School H  12 18</span></span></code></pre></div>
<p>To fit the model in <em>baggr</em> (having followed the installation
instructions and loaded the package):</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a>baggr_schools <span class="ot">&lt;-</span> <span class="fu">baggr</span>(schools, <span class="at">model =</span> <span class="st">&quot;rubin&quot;</span>, <span class="at">pooling =</span> <span class="st">&quot;partial&quot;</span>)</span></code></pre></div>
<p>This creates a <code>baggr</code> class object, and you can access
the underlying <code>stanfit</code> object by calling
<code>baggr_schools$fit</code>. If you don’t change the default priors,
then <em>baggr</em> will print a message informing you of the priors it
has chosen.</p>
<p>Printing <code>baggr_schools</code> returns a summary of the
posterior inference. First <em>baggr</em> records the model type and the
pooling regime chosen by the user or implemented by default. Second,
<em>baggr</em> returns inference on the aggregate treatment effect <span class="math inline">\(\tau\)</span> by reporting its posterior mean and
95% uncertainty interval, and similar inference on the hyper-SD <span class="math inline">\(\sigma_{\tau}\)</span>. Lastly, it prints the
“updated” inference on each of the groups’ treatment effects, displaying
their new posterior means, standard deviations and pooling factors (see
below).</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a><span class="fu">print</span>(baggr_schools)</span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a><span class="co">#&gt; Model type: Rubin model with aggregate data </span></span>
<span id="cb4-3"><a href="#cb4-3" tabindex="-1"></a><span class="co">#&gt; Pooling of effects: partial </span></span>
<span id="cb4-4"><a href="#cb4-4" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb4-5"><a href="#cb4-5" tabindex="-1"></a><span class="co">#&gt; Aggregate treatment effect (on mean), 8 groups:</span></span>
<span id="cb4-6"><a href="#cb4-6" tabindex="-1"></a><span class="co">#&gt; Hypermean (tau) =  8.3 with 95% interval -1.8 to 22.0 </span></span>
<span id="cb4-7"><a href="#cb4-7" tabindex="-1"></a><span class="co">#&gt; Hyper-SD (sigma_tau) = 6.93 with 95% interval 0.26 to 23.09 </span></span>
<span id="cb4-8"><a href="#cb4-8" tabindex="-1"></a><span class="co">#&gt; Posterior predictive effect = 8.4 with 95% interval -12.0 to 32.0 </span></span>
<span id="cb4-9"><a href="#cb4-9" tabindex="-1"></a><span class="co">#&gt; Total pooling (1 - I^2) = 0.75 with 95% interval 0.20 to 1.00 </span></span>
<span id="cb4-10"><a href="#cb4-10" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb4-11"><a href="#cb4-11" tabindex="-1"></a><span class="co">#&gt; Group-specific treatment effects:</span></span>
<span id="cb4-12"><a href="#cb4-12" tabindex="-1"></a><span class="co">#&gt;          mean  sd   2.5%  50% 97.5% pooling</span></span>
<span id="cb4-13"><a href="#cb4-13" tabindex="-1"></a><span class="co">#&gt; School A 11.7 8.8  -2.47 10.3    33    0.81</span></span>
<span id="cb4-14"><a href="#cb4-14" tabindex="-1"></a><span class="co">#&gt; School B  7.9 6.3  -5.10  8.0    20    0.71</span></span>
<span id="cb4-15"><a href="#cb4-15" tabindex="-1"></a><span class="co">#&gt; School C  6.2 8.0 -11.66  6.8    21    0.83</span></span>
<span id="cb4-16"><a href="#cb4-16" tabindex="-1"></a><span class="co">#&gt; School D  7.6 6.6  -6.07  7.6    21    0.74</span></span>
<span id="cb4-17"><a href="#cb4-17" tabindex="-1"></a><span class="co">#&gt; School E  4.9 6.4  -9.28  5.5    16    0.68</span></span>
<span id="cb4-18"><a href="#cb4-18" tabindex="-1"></a><span class="co">#&gt; School F  5.9 6.5  -8.18  6.3    18    0.74</span></span>
<span id="cb4-19"><a href="#cb4-19" tabindex="-1"></a><span class="co">#&gt; School G 10.9 7.0  -0.63 10.0    27    0.71</span></span>
<span id="cb4-20"><a href="#cb4-20" tabindex="-1"></a><span class="co">#&gt; School H  8.6 7.8  -6.52  8.2    26    0.85</span></span></code></pre></div>
<!-- This is quite similar to the output from the version of the model suggested in ["How to use rstan"](https://github.com/stan-dev/rstan/wiki/RStan-Getting-Started) tutorial, the small difference probably arising from the different default priors. -->
<div id="choosing-priors" class="section level3">
<h3>Choosing priors</h3>
<p>It is possible to fit the Rubin model without specifying any priors,
in which case the user is notified about the automatic prior choice that
<em>baggr</em> performs. But the priors can also be easily customised by
using <code>prior_</code> arguments to <code>baggr()</code>. The Rubin
model performs univariate shrinkage so we will not need to specify a
hyper-correlation prior, but we can specify some custom priors on the
hyper-mean and hyper-sd. If desired, the user can specify only some
priors as custom distributions - the rest will be chosen automatically
and the user will be notified of this in the output.</p>
<p>Consider changing both as an example, say placing a Normal prior with
mean -5 and standard deviation 10 on our hypermean <span class="math inline">\(\tau\)</span>, as well as placing a uniform prior
with lower bound 0 and upper bound 5 on our hyper-standard-deviation
<span class="math inline">\(\sigma_{\tau}\)</span>. Thus, what is
expressed mathematically as <span class="math inline">\(\tau \sim
N(-5,10)\)</span> and <span class="math inline">\(\sigma_{\tau} \sim
U[0,5]\)</span> is expressed in baggr as follows:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a><span class="fu">baggr</span>(schools, <span class="st">&quot;rubin&quot;</span>, </span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a>      <span class="at">prior_hypermean =</span> <span class="fu">normal</span>(<span class="sc">-</span><span class="dv">5</span>, <span class="dv">10</span>),</span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a>      <span class="at">prior_hypersd   =</span> <span class="fu">uniform</span>(<span class="dv">0</span>, <span class="dv">5</span>))</span></code></pre></div>
<!-- #[WORKING SECTION Suppose you have the full individual-level dataset for all groups (case 3 above) but still wish to run the Rubin model: _baggr_ can do this automatically, you do not need to manually estimate the group-specific effects and standard errors yourself. To see how it works, check out the microcredit dataset analysed in Meager (2019) which is stored in _baggr_ as the data frame "microcredit". Have a look at the tail of the data frame, which tells you that these households are from the "Tarozzi" et al study group (the Ethiopia trial), for which we have expenditures, revenue and profit data, as well as the treatment indicator. -->
<!-- # ```{r} -->
<!-- # tail(microcredit) -->
<!-- # ``` -->
<!-- # _baggr_ will only understand the 3 types of formatting described above, and while we have already stacked this dataset, we now need to choose a single outcome to focus on.  ] -->
<p>It is also possible to pass your custom priors as a list to baggr, as
follows:</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a>custom_priors <span class="ot">&lt;-</span> <span class="fu">list</span>( <span class="at">hypermean =</span> <span class="fu">cauchy</span>(<span class="dv">0</span>,<span class="dv">25</span>), <span class="at">hypersd =</span> <span class="fu">normal</span>(<span class="dv">0</span>,<span class="dv">30</span>))</span>
<span id="cb6-2"><a href="#cb6-2" tabindex="-1"></a><span class="fu">baggr</span>(schools, <span class="st">&quot;rubin&quot;</span>, <span class="at">pooling =</span> <span class="st">&quot;partial&quot;</span>, <span class="at">prior =</span> custom_priors)</span></code></pre></div>
<p>Note that the Rubin model assumes Gaussian distribution of effects
across groups. This is generally appropriate as a first pass at the
problem (see <span class="citation">McCulloch and Neuhaus (2011)</span>)
<em>except</em> if the distribution is known to be asymmetric for
scientific reasons. For example, if you are working with risk ratios or
odds ratios these statistics cannot be negative and the chosen
hyper-distribution should typically reflect that. However, in many cases
it is possible and indeed standard to maintain the Gaussian assumption
on a transform of the object: for example, you can safely fit the Rubin
model to the logarithm of the risk ratios or odds ratios. While bearing
in mind that log transforms obscure inherent dependencies between means
and variances in the raw scale, this is still much better than applying
a Gaussian to the raw object itself.</p>
</div>
</div>
<div id="understanding-and-criticising-baggr-model-performance" class="section level2">
<h2>Understanding and criticising <em>baggr</em> model performance</h2>
<p><em>Baggr</em> models are run in Stan, and the fit and results need
to be checked, understood and criticised as you would any stan model or
indeed any MCMC model fitting exercise. <strong>You must pay attention
to printed warnings about the Rhat criterion: if you see a warning that
Rhat statistic exceeds 1.05 for any parameter, you MUST NOT use the
results for inference.</strong> This warning means the MCMC chains have
not converged, and it is exceedingly unlikely that the “posterior
inference” printed out corresponds to anything close to the true
posterior implied by your model and data. <strong>If you use results
from which the Rhat statistic exceeds 1.05 YOUR INFERENCE WILL BE
WRONG.</strong></p>
<p>If you see this warning, try re-running the model with the option
<code>iter</code> set to a large number such as 10,000, as below. It is
also good practice to run many chains, such as 8 rather than the default
4, to have a greater chance to detect pathological MCMC behaviour. You
do this by passing <em>baggr</em> the stan arguments
<code>iter = 10000</code> and <code>chains = 8</code>, like so:</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a>baggr_schools <span class="ot">&lt;-</span> <span class="fu">baggr</span>(schools, <span class="at">model =</span> <span class="st">&quot;rubin&quot;</span>, <span class="at">pooling =</span> <span class="st">&quot;partial&quot;</span>, </span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a>                       <span class="at">iter =</span> <span class="dv">10000</span>, <span class="at">chains =</span> <span class="dv">8</span>)</span></code></pre></div>
<p>Other warnings you may see involve “divergent transitions”. While not
as serious as high Rhat, this can signal problems with the model. As the
stan message that you will see suggests, try adjusting
<code>adapt_delta</code> argument above 0.8, e.g. to 0.99. You cannot
pass this parameter directly to <em>stan</em> and thus you cannot pass
it directly to baggr, so instead you must pass the argument
<code>control = list(adapt_delta = 0.99)</code>.</p>
</div>
<div id="measuring-pooling" class="section level2">
<h2>Measuring “pooling”</h2>
<p>It is often useful to measure the extent to which the hierarchical
model is “pooling” or sharing information across the groups in the
process of aggregation. <em>Baggr</em> automatically computes and prints
such a metric, as seen above. You can access more details by writing
<code>pooling(baggr_schools)</code> or
<code>heterogeneity(baggr_schools)</code>.</p>
<div id="estimate-of-pooling-in-each-group" class="section level3">
<h3>Estimate of pooling in each group</h3>
<p>In the output above we can see a “pooling” column next to each group.
This is a statistic due to <span class="citation">Gelman and Pardoe
(2006)</span>.</p>
<p>In a partial pooling model (see [baggr]), group <span class="math inline">\(k\)</span> (e.g. study) has a treatment effect
estimate, with some SE around the real <span class="math inline">\(\tau_k\)</span>, i.e. <span class="math inline">\(\hat{\tau_k} \sim \mathcal{N}(\tau_k,
\hat{se_k})\)</span> ( itself is an estimate of the true <span class="math inline">\(se_k\)</span>). Each <span class="math inline">\(\tau_k\)</span> itself is distributed with mean
<span class="math inline">\(\tau\)</span> and variance <span class="math inline">\(\sigma_{\tau}^2\)</span>.</p>
<p>The quantity of interest is ratio of variability in <span class="math inline">\(\tau\)</span> to total variability. By convention,
we subtract it from 1, to obtain a <em>pooling metric</em> <span class="math inline">\(p\)</span>.</p>
<p><span class="math display">\[p = 1 -
\frac{\sigma_{\tau}^2}{\sigma_{\tau}^2 + se_k^2}\]</span></p>
<ul>
<li>If <span class="math inline">\(p &lt; 0.5\)</span>, that means the
variation across studies is higher than variation within studies.</li>
<li>Values close to 1 indicate nearly full pooling. Variation across
studies dominates.</li>
<li>Values close to 0 – no pooling. Variation within studies
dominates.</li>
</ul>
<p>Note that, since <span class="math inline">\(\sigma_{\tau}^2\)</span>
is a Bayesian parameter (rather than a single fixed value) <span class="math inline">\(p\)</span> is also a parameter. It is typical for
<span class="math inline">\(p\)</span> to have very high dispersion, as
in many cases we cannot precisely estimate <span class="math inline">\(\sigma_{\tau}\)</span>. That is certainly the case
in our example:</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a><span class="fu">pooling</span>(baggr_schools)</span>
<span id="cb8-2"><a href="#cb8-2" tabindex="-1"></a><span class="co">#&gt; , , 1</span></span>
<span id="cb8-3"><a href="#cb8-3" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb8-4"><a href="#cb8-4" tabindex="-1"></a><span class="co">#&gt;            [,1]      [,2]      [,3]      [,4]      [,5]      [,6]      [,7]</span></span>
<span id="cb8-5"><a href="#cb8-5" tabindex="-1"></a><span class="co">#&gt; 2.5%  0.2967497 0.1579246 0.3243730 0.1849549 0.1318760 0.1849549 0.1579246</span></span>
<span id="cb8-6"><a href="#cb8-6" tabindex="-1"></a><span class="co">#&gt; mean  0.8139490 0.7089556 0.8282654 0.7357306 0.6781800 0.7357306 0.7089556</span></span>
<span id="cb8-7"><a href="#cb8-7" tabindex="-1"></a><span class="co">#&gt; 97.5% 0.9996918 0.9993067 0.9997291 0.9994270 0.9991442 0.9994270 0.9993067</span></span>
<span id="cb8-8"><a href="#cb8-8" tabindex="-1"></a><span class="co">#&gt;            [,8]</span></span>
<span id="cb8-9"><a href="#cb8-9" tabindex="-1"></a><span class="co">#&gt; 2.5%  0.3779680</span></span>
<span id="cb8-10"><a href="#cb8-10" tabindex="-1"></a><span class="co">#&gt; mean  0.8525197</span></span>
<span id="cb8-11"><a href="#cb8-11" tabindex="-1"></a><span class="co">#&gt; 97.5% 0.9997859</span></span></code></pre></div>
</div>
<div id="overall-pooling-in-the-model" class="section level3">
<h3>Overall pooling (in the model)</h3>
<p>Sometimes researchers prefer to summarise heterogeneity by using a
single measure. One possibility is to provide a “big” estimate of
pooling <span class="math inline">\(P\)</span> is analogous to averaging
<span class="math inline">\(p\)</span> across groups:</p>
<p><span class="math display">\[P = 1 -
\frac{\sigma_{\tau}^2}{\sigma_{\tau}^2 + \text{E}(se_k^2)}\]</span></p>
<p>where is average over <span class="math inline">\(K\)</span> groups.
Note that the denominator in the formula above is an application of the
law of total variance to <span class="math inline">\(\hat{\tau_k}\)</span>, i.e. <span class="math inline">\(\text{Var}(\hat{\tau_k})\)</span> is a sum of
between-study variance (<span class="math inline">\(\text{Var}({\tau_k})\)</span>) and average
within-study variance (<span class="math inline">\(\text{E}(se_k^2)\)</span>); <span class="citation">von Hippel (2015)</span> provides more details.</p>
<p>In many contexts, i.e. medical statistics, it is typical to report
<span class="math inline">\(1-P\)</span>, called <span class="math inline">\(I^2\)</span> (see <span class="citation">Higgins
et al. (2003)</span> for an overview). Higher values of
<em>I-squared</em> indicate higher heterogeneity.</p>
<p>Same as for group-specific estimates, <span class="math inline">\(P\)</span> is a Bayesian parameter and its
dispersion can be high.</p>
</div>
</div>
<div id="plotting-and-model-comparison-in-baggr" class="section level2">
<h2>Plotting and model comparison in <em>baggr</em></h2>
<p>A fundamental step to understanding the model is to plot the
posterior distributions. <em>baggr</em> has several automatic plot
functions which you can access by calling <code>baggr_plot()</code> or,
equivalently, using the default plot function; these visuals are based
on <em>bayesplot</em> package. Plotting functions always take
<code>baggr</code> class object as their first argument. By default,
means and 95% posterior intervals of the effects <em>in each group</em>
are shown. Extra options are available, such as whether to order the
results by effect size. For the 8 schools Rubin model we have</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a><span class="fu">plot</span>(baggr_schools, <span class="at">order =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<p><img src="data:image/png;base64,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" /><!-- --></p>
<p>Similarly important is the plot of potential treatment effects
(posterior predictive distribution), obtained by repeatedly drawing
hypermean and hyper-SD values from baggr’s Markov Chain model, then
drawing new value of treatment effect conditional on these:</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a><span class="fu">effect_plot</span>(baggr_schools)</span></code></pre></div>
<p><img src="data:image/png;base64,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" /><!-- --></p>
<p>The values underlying the plot can be obtained by
<code>effect_draw</code>, which can be used e.g. to draw 1 new
value:</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" tabindex="-1"></a><span class="fu">effect_draw</span>(baggr_schools, <span class="at">draws =</span> <span class="dv">1</span>)</span>
<span id="cb11-2"><a href="#cb11-2" tabindex="-1"></a><span class="co">#&gt; [1] -0.7846135</span></span></code></pre></div>
<p>You can also summarise over the entire distribution to obtain mean,
SD, and quantiles
(<code>effect_draw(baggr_schools, summary = TRUE)</code>). For
meta-regression models (models with covariates), you can also use this
function to make predictions for new data, at set values of
covariates.</p>
<p>However, from the viewpoint of model building, the most important
plots are the ones that directly compare many possible models.</p>
<div id="basic-model-comparison-with-baggr_compare" class="section level3">
<h3>Basic model comparison with <em>baggr_compare</em></h3>
<p>The default Rubin model (which we have selected explicitly above) is
that of partial pooling. When using <code>baggr_compare</code> without
any extra arguments, full pooling, no pooling and partial pooling
versions of the model will be fit:</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" tabindex="-1"></a>my_baggr_comparison <span class="ot">&lt;-</span> <span class="fu">baggr_compare</span>(schools)</span></code></pre></div>
<p>The result of the comparison includes all the models, but it also
produces an automatic comparison plot. Because the output object of
baggr_compare is a <code>ggplot</code> object you can edit it further
yourself and build on it as you would any <code>ggplot</code> object by,
for example, changing theme or labels:</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" tabindex="-1"></a><span class="fu">plot</span>(my_baggr_comparison) <span class="sc">+</span> </span>
<span id="cb13-2"><a href="#cb13-2" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">&quot;8 schools: model comparison&quot;</span>)</span></code></pre></div>
<p><img src="data:image/png;base64,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" /><!-- --></p>
</div>
<div id="comparing-existing-models-understanding-impact-of-the-prior" class="section level3">
<h3>Comparing existing models, understanding impact of the prior</h3>
<p>The comparison can be made not just for different types of pooling,
but for any number of models which include the same groups. A typical
example is comparing two models on the same data, but with different
priors.</p>
<p>Consider this model with alternative, very strong priors:</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" tabindex="-1"></a>baggr_schools_v2 <span class="ot">&lt;-</span> <span class="fu">baggr</span>(schools, <span class="at">prior_hypermean =</span> <span class="fu">normal</span>(<span class="dv">10</span>, <span class="fl">2.5</span>))</span></code></pre></div>
<p>We can compare it with the previous model by providing both models as
arguments to <code>baggr_compare</code> and <code>effects_plot</code>.
It’s good to name the arguments, as these names will be used to label
them:</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" tabindex="-1"></a><span class="fu">effect_plot</span>(<span class="st">&quot;Default model&quot;</span> <span class="ot">=</span> baggr_schools, <span class="st">&quot;normal(10, 2.5)&quot;</span> <span class="ot">=</span> baggr_schools_v2) <span class="sc">+</span></span>
<span id="cb15-2"><a href="#cb15-2" tabindex="-1"></a>  <span class="fu">coord_cartesian</span>(<span class="at">xlim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">10</span>, <span class="dv">30</span>)) <span class="sc">+</span> <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">&quot;top&quot;</span>)</span></code></pre></div>
<p><img src="data:image/png;base64,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" /><!-- --></p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" tabindex="-1"></a><span class="fu">baggr_compare</span>(<span class="st">&quot;Default model&quot;</span> <span class="ot">=</span> baggr_schools, <span class="st">&quot;normal(10, 2.5)&quot;</span> <span class="ot">=</span> baggr_schools_v2)</span>
<span id="cb16-2"><a href="#cb16-2" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb16-3"><a href="#cb16-3" tabindex="-1"></a><span class="co">#&gt; Mean treatment effects:</span></span>
<span id="cb16-4"><a href="#cb16-4" tabindex="-1"></a><span class="co">#&gt;                     2.5%    mean   97.5%  median      sd</span></span>
<span id="cb16-5"><a href="#cb16-5" tabindex="-1"></a><span class="co">#&gt; Default model   -1.77837 8.29902 22.0418 7.91293 5.93786</span></span>
<span id="cb16-6"><a href="#cb16-6" tabindex="-1"></a><span class="co">#&gt; normal(10, 2.5)  5.18573 9.51974 13.9187 9.48642 2.21891</span></span>
<span id="cb16-7"><a href="#cb16-7" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb16-8"><a href="#cb16-8" tabindex="-1"></a><span class="co">#&gt; SD for treatment effects:</span></span>
<span id="cb16-9"><a href="#cb16-9" tabindex="-1"></a><span class="co">#&gt;                     2.5%    mean   97.5%  median      sd</span></span>
<span id="cb16-10"><a href="#cb16-10" tabindex="-1"></a><span class="co">#&gt; Default model   0.263394 6.92524 23.0915 5.54017 5.93912</span></span>
<span id="cb16-11"><a href="#cb16-11" tabindex="-1"></a><span class="co">#&gt; normal(10, 2.5) 0.219007 5.84283 17.6026 4.71528 4.67683</span></span>
<span id="cb16-12"><a href="#cb16-12" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb16-13"><a href="#cb16-13" tabindex="-1"></a><span class="co">#&gt; Posterior predictive effects:</span></span>
<span id="cb16-14"><a href="#cb16-14" tabindex="-1"></a><span class="co">#&gt;                      2.5%    mean   97.5%  median       sd</span></span>
<span id="cb16-15"><a href="#cb16-15" tabindex="-1"></a><span class="co">#&gt; Default model   -13.28690 8.28680 31.9200 7.76553 11.24630</span></span>
<span id="cb16-16"><a href="#cb16-16" tabindex="-1"></a><span class="co">#&gt; normal(10, 2.5)  -7.91404 9.45364 27.1755 9.39610  8.08842</span></span></code></pre></div>
</div>
<div id="forest-plots-for-the-models" class="section level3">
<h3>Forest plots for the models</h3>
<p>Forest plots are a typical for reporting meta-analysis results. We
adapted the default functionality from <em>forestplot</em> to work with
<em>baggr</em> objects. You can choose to display 1) input data for
groups, and/or, 2) posterior distributions for groups. In both cases
these are followed by a display mean treatment effect. The default is
1):</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" tabindex="-1"></a><span class="fu">forest_plot</span>(baggr_schools)</span></code></pre></div>
<p><img src="data:image/png;base64,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" /><!-- --></p>
<p>The plots can be modified by passing extra arguments – see
<code>?forestplot</code>. It’s also possible to display both 1) and
2):</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" tabindex="-1"></a><span class="fu">forest_plot</span>(baggr_schools, <span class="at">show =</span> <span class="st">&quot;both&quot;</span>)</span></code></pre></div>
<p><img src="data:image/png;base64,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" /><!-- --></p>
</div>
</div>
<div id="cross-validation-in-baggr" class="section level2">
<h2>Cross-validation in <em>baggr</em></h2>
<p><em>Baggr</em> has built-in, automated leave-one-out cross validation
for its models. The values returned by <code>loocv()</code> can be used
to understand how any one group affects the overall result, as well as
how well the model predicts the omitted group.</p>
<p>This function automatically runs <span class="math inline">\(K\)</span> baggr models, leaving out one group at
a time, and then calculates expected log predictive density (ELPD) for
that group (see <span class="citation">Gelman, Hwang, and Vehtari
(2014)</span>). The main output is the cross-validation information
criterion, or -2 times the ELPD averaged over <span class="math inline">\(K\)</span> models. This is related to, and often
approximated by, the Watanabe-Akaike Information Criterion. A value
closer to zero (i.e. a smaller number in magnitude) means a better fit.
For more information on cross-validation see this <a href="http://www.stat.columbia.edu/~gelman/research/published/waic_understand3.pdf">overview
article</a>.</p>
<p>Therefore, if you have <span class="math inline">\(K\)</span> groups,
using the <code>loocv()</code> will run your model of choice <span class="math inline">\(K\)</span> times. Be aware that this may take a
while even for simple models. (You should see a progress bar in your
terminal window.) The <code>loocv()</code> function takes in the same
arguments as <code>baggr()</code>, plus an option
(<code>return_models</code>) for whether to return all the models or
just the summary statistics. For the 8 schools example we can do</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" tabindex="-1"></a>loocv_res <span class="ot">&lt;-</span> <span class="fu">loocv</span>(schools, <span class="at">return_models =</span> <span class="cn">FALSE</span>, </span>
<span id="cb19-2"><a href="#cb19-2" tabindex="-1"></a>                   <span class="at">iter =</span> <span class="dv">1000</span>, <span class="co">#just to make it a bit faster -- don&#39;t try it at home!</span></span>
<span id="cb19-3"><a href="#cb19-3" tabindex="-1"></a>                   <span class="at">model =</span> <span class="st">&quot;rubin&quot;</span>, <span class="at">pooling =</span> <span class="st">&quot;partial&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" tabindex="-1"></a>loocv_res</span>
<span id="cb20-2"><a href="#cb20-2" tabindex="-1"></a><span class="co">#&gt; LOO estimate based on 8-fold cross-validation</span></span>
<span id="cb20-3"><a href="#cb20-3" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb20-4"><a href="#cb20-4" tabindex="-1"></a><span class="co">#&gt;       Estimate Standard Error</span></span>
<span id="cb20-5"><a href="#cb20-5" tabindex="-1"></a><span class="co">#&gt; elpd     -31.7          0.954</span></span>
<span id="cb20-6"><a href="#cb20-6" tabindex="-1"></a><span class="co">#&gt; looic     63.5          1.910</span></span></code></pre></div>
<p>The <code>loocv()</code> output contains more than just the matrix it
prints, and this additional information can be accessed via
<code>attributes()</code>, e.g. the mean treatment effects, their
variability and <em>elpd</em> for each model that are stored in the
attribute <code>df</code>:</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" tabindex="-1"></a><span class="fu">names</span>(<span class="fu">attributes</span>(loocv_res))</span>
<span id="cb21-2"><a href="#cb21-2" tabindex="-1"></a><span class="co">#&gt; [1] &quot;names&quot; &quot;class&quot;</span></span>
<span id="cb21-3"><a href="#cb21-3" tabindex="-1"></a><span class="fu">attr</span>(loocv_res, <span class="st">&quot;df&quot;</span>)</span>
<span id="cb21-4"><a href="#cb21-4" tabindex="-1"></a><span class="co">#&gt; NULL</span></span></code></pre></div>
<p>This data frame can then be used to examine or compute the variation
in the inference on <span class="math inline">\(\tau\)</span> in the
absence of each group. If the user is interested in manually checking
the consequences of excluding a particular group or set of groups, this
is also possible in <em>baggr</em> using subsetting. For example,
suppose that we want to run the Rubin model on school groups 1-7 and
predict the effect in the 8th school. The code below shows how you can
specify a subset of the dataframe as your “data” argument, and then
designate another subset as the “testing” holdout set by assigning it to
the argument “test_data” in the baggr command. Here we have done it for
both partial and full pooling:</p>
<p>We can compare the performance of the two models using the mean log
predictive density. This itself is a density as the name suggests so we
will compute the log expected value of this density: here, as before, a
number closer to zero is better. In this case the full pooling model
actually does slightly better:</p>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" tabindex="-1"></a>fit1<span class="sc">$</span>mean_lpd</span>
<span id="cb22-2"><a href="#cb22-2" tabindex="-1"></a><span class="co">#&gt; [1] 7.945999</span></span>
<span id="cb22-3"><a href="#cb22-3" tabindex="-1"></a>fit2<span class="sc">$</span>mean_lpd</span>
<span id="cb22-4"><a href="#cb22-4" tabindex="-1"></a><span class="co">#&gt; [1] 7.728722</span></span></code></pre></div>
<p>If we run the full <code>loocv</code> for both models, we can
estimate the difference between the ELPD of those models as well as the
standard error of that difference. As an example, let’s consider the two
models above.</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" tabindex="-1"></a>loocv_full <span class="ot">&lt;-</span> <span class="fu">loocv</span>(<span class="at">data =</span> schools, </span>
<span id="cb23-2"><a href="#cb23-2" tabindex="-1"></a>                    <span class="at">model =</span> <span class="st">&quot;rubin&quot;</span>, </span>
<span id="cb23-3"><a href="#cb23-3" tabindex="-1"></a>                    <span class="at">pooling =</span> <span class="st">&quot;full&quot;</span>)</span></code></pre></div>
<p>We can compare those fits with <code>loo_compare</code>, which gives
use the differences in ELPD for the various models we pass it. Generally
it is important to pay attention to <em>both</em> the difference in the
predictive density and also the standard error of that difference.</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" tabindex="-1"></a><span class="fu">loo_compare</span>(loocv_res, loocv_full)</span>
<span id="cb24-2"><a href="#cb24-2" tabindex="-1"></a><span class="co">#&gt; Comparison of cross-validation</span></span>
<span id="cb24-3"><a href="#cb24-3" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb24-4"><a href="#cb24-4" tabindex="-1"></a><span class="co">#&gt;                     ELPD ELPD SE</span></span>
<span id="cb24-5"><a href="#cb24-5" tabindex="-1"></a><span class="co">#&gt; Model 1 - Model 2 -0.697   0.355</span></span>
<span id="cb24-6"><a href="#cb24-6" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb24-7"><a href="#cb24-7" tabindex="-1"></a><span class="co">#&gt; Positive ELPD indicates the reference group is preferred.</span></span></code></pre></div>
</div>
<div id="references" class="section level2 unnumbered">
<h2 class="unnumbered">References</h2>
<div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0">
<div id="ref-gelman_bayesian_2013" class="csl-entry">
Gelman, Andrew, John B. Carlin, Hal S. Stern, David B. Dunson, Aki
Vehtari, and Donald B. Rubin. 2013. <em>Bayesian <span>Data
Analysis</span></em>. <span>CRC Press</span>.
</div>
<div id="ref-gelman_understanding_2014" class="csl-entry">
Gelman, Andrew, Jessica Hwang, and Aki Vehtari. 2014.
<span>“Understanding Predictive Information Criteria for
<span>Bayesian</span> Models.”</span> <em>Statistics and Computing</em>
24 (6): 997–1016. <a href="https://doi.org/10.1007/s11222-013-9416-2">https://doi.org/10.1007/s11222-013-9416-2</a>.
</div>
<div id="ref-gelman_bayesian_2006" class="csl-entry">
Gelman, Andrew, and Iain Pardoe. 2006. <span>“Bayesian
<span>Measures</span> of <span>Explained Variance</span> and
<span>Pooling</span> in <span>Multilevel</span>
(<span>Hierarchical</span>) <span>Models</span>.”</span>
<em>Technometrics</em> 48 (2): 241–51. <a href="https://doi.org/10.1198/004017005000000517">https://doi.org/10.1198/004017005000000517</a>.
</div>
<div id="ref-higgins_measuring_2003-2" class="csl-entry">
Higgins, Julian P T, Simon G Thompson, Jonathan J Deeks, and Douglas G
Altman. 2003. <span>“Measuring Inconsistency in Meta-Analyses.”</span>
<em>BMJ : British Medical Journal</em> 327 (7414): 557–60.
</div>
<div id="ref-mcculloch_misspecifying_2011" class="csl-entry">
McCulloch, Charles E., and John M. Neuhaus. 2011. <span>“Misspecifying
the <span>Shape</span> of a <span>Random Effects Distribution</span>:
<span>Why Getting It Wrong May Not Matter</span>.”</span>
<em>Statistical Science</em> 26 (3): 388–402.
</div>
<div id="ref-meager_aggregating_2019-1" class="csl-entry">
Meager, Rachael. 2019. <span>“Aggregating <span>Distributional Treatment
Effects</span>: <span>A Bayesian Hierarchical Analysis</span> of the
<span>Microcredit Literature</span>.”</span> <a href="https://doi.org/10.31222/osf.io/7tkvm">https://doi.org/10.31222/osf.io/7tkvm</a>.
</div>
<div id="ref-rubin_estimating_1974" class="csl-entry">
Rubin, Donald B. 1974. <span>“Estimating <span>Causal Effects</span> of
<span>Treatments</span> in <span>Randomized</span> and
<span>Nonrandomized Studies</span>.”</span> <em>Journal of Educational
Psychology</em>.
</div>
<div id="ref-rubin_estimation_1981" class="csl-entry">
———. 1981. <span>“Estimation in <span>Parallel Randomized
Experiments</span>.”</span> <em>Journal of Educational Statistics</em> 6
(4): 377–401.
</div>
<div id="ref-von_hippel_heterogeneity_2015" class="csl-entry">
von Hippel, Paul T. 2015. <span>“The Heterogeneity Statistic
<span>I2</span> Can Be Biased in Small Meta-Analyses.”</span> <em>BMC
Medical Research Methodology</em> 15 (April). <a href="https://doi.org/10.1186/s12874-015-0024-z">https://doi.org/10.1186/s12874-015-0024-z</a>.
</div>
</div>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
